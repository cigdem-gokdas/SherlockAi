import os
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma

# KlasÃ¶r yollarÄ±
DATA_PATH = "./data"
DB_PATH = "./chroma_db"

def create_vector_db():
    print("ğŸ•µï¸â€â™‚ï¸ SherlockAi Veri YÃ¼kleyicisi BaÅŸlatÄ±lÄ±yor...")
    if not os.path.exists(DATA_PATH):
        print(f"HATA: '{DATA_PATH}' klasÃ¶rÃ¼ bulunamadÄ±!")
        return
    
    print("ğŸ“š Kitaplar okunuyor...")
    loader = DirectoryLoader(DATA_PATH, glob="./*.txt", loader_cls=TextLoader, loader_kwargs={'encoding': 'utf-8'})
    documents = loader.load()
    print(f"âœ… Toplam {len(documents)} kitap/belge yÃ¼klendi.")

    print("âœ‚ï¸  Metinler parÃ§alanÄ±yor...")
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
    chunks = text_splitter.split_documents(documents)
    print(f"ğŸ§© {len(chunks)} veri parÃ§acÄ±ÄŸÄ± oluÅŸturuldu.")

    print("ğŸ§  Embedding modeli hazÄ±rlanÄ±yor (Bu biraz sÃ¼rebilir)...")
    embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")

    print("ğŸ’¾ VeritabanÄ±na kaydediliyor...")
    vector_db = Chroma.from_documents(documents=chunks, embedding=embedding_model, persist_directory=DB_PATH)
    print(f"ğŸ‰ Ä°ÅLEM BAÅARILI! VeritabanÄ± oluÅŸturuldu.")

if __name__ == "__main__":
    create_vector_db()
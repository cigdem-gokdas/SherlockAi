import os
import json
import shutil
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_chroma import Chroma
from langchain_core.documents import Document

# KlasÃ¶r yollarÄ±
DATA_PATH = "./data"
DB_PATH = "./chroma_db"

def load_json_files(directory):
    """JSON formatÄ±ndaki diyalog dosyalarÄ±nÄ± okur."""
    documents = []
    if not os.path.exists(directory):
        return documents
        
    for filename in os.listdir(directory):
        if filename.endswith(".json"):
            file_path = os.path.join(directory, filename)
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    # JSON liste mi sÃ¶zlÃ¼k mÃ¼ kontrol et
                    if isinstance(data, list):
                        items = data
                    else:
                        items = [data] # Tek objeyse listeye Ã§evir

                    for item in items:
                        # Ä°Ã§erik oluÅŸtur
                        content = f"Rol: {item.get('rol', 'Bilinmiyor')}\n"
                        content += f"Karakteristik: {item.get('karakteristik', '')}\n"
                        content += "Ã–rnek KonuÅŸma TarzÄ±:\n"
                        if 'ornek_cumleler' in item:
                            for ornek in item['ornek_cumleler']:
                                content += f"- {ornek}\n"
                        
                        # Belgeye dÃ¶nÃ¼ÅŸtÃ¼r
                        documents.append(Document(page_content=content, metadata={"source": filename, "type": "dialogue_style"}))
            except Exception as e:
                print(f"âš ï¸ {filename} okunurken hata: {e}")
    return documents

def create_vector_db():
    print("ğŸ•µï¸â€â™‚ï¸ Veri YÃ¼kleyicisi BaÅŸlatÄ±lÄ±yor...")
    
    # KlasÃ¶r kontrolÃ¼
    if not os.path.exists(DATA_PATH):
        os.makedirs(DATA_PATH)
        print(f"âš ï¸ '{DATA_PATH}' klasÃ¶rÃ¼ oluÅŸturuldu. LÃ¼tfen iÃ§ine .txt kitaplarÄ± ve .json dosyalarÄ±nÄ± atÄ±p tekrar Ã§alÄ±ÅŸtÄ±rÄ±n.")
        return

    # 1. Metin DosyalarÄ±nÄ± YÃ¼kle (.txt)
    print("ğŸ“š Kitaplar (.txt) taranÄ±yor...")
    txt_loader = DirectoryLoader(DATA_PATH, glob="./*.txt", loader_cls=TextLoader, loader_kwargs={'encoding': 'utf-8'})
    book_docs = txt_loader.load()
    
    # 2. JSON DosyalarÄ±nÄ± YÃ¼kle (.json)
    print("ğŸ­ Karakter DiyaloglarÄ± (.json) taranÄ±yor...")
    json_docs = load_json_files(DATA_PATH)
    
    all_docs = book_docs + json_docs
    
    if not all_docs:
        print("âŒ HATA: 'data' klasÃ¶rÃ¼nde hiÃ§ dosya bulunamadÄ±!")
        return

    print(f"âœ… Toplam {len(all_docs)} parÃ§a veri bulundu.")

    # 3. ParÃ§alama
    print("âœ‚ï¸  Veriler iÅŸleniyor...")
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
    chunks = text_splitter.split_documents(all_docs)

    # 4. Embedding (TÃœRKÃ‡E Ä°Ã‡Ä°N KRÄ°TÄ°K NOKTA)
    # ollama.py ile aynÄ± model olmak ZORUNDA
    print("ğŸ§  Yapay zeka modeli hazÄ±rlanÄ±yor (paraphrase-multilingual-MiniLM-L12-v2)...")
    embedding_model = HuggingFaceEmbeddings(model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")

    # 5. VeritabanÄ±nÄ± Temizle ve OluÅŸtur
    if os.path.exists(DB_PATH):
        print("ğŸ—‘ï¸  Eski veritabanÄ± temizleniyor...")
        shutil.rmtree(DB_PATH)

    print("ğŸ’¾ VeritabanÄ± kaydediliyor...")
    Chroma.from_documents(documents=chunks, embedding=embedding_model, persist_directory=DB_PATH)
    print("ğŸ‰ Ä°ÅLEM TAMAM! VeritabanÄ± hazÄ±r.")

if __name__ == "__main__":
    create_vector_db()